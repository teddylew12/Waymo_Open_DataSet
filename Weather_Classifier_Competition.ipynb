{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Competition\n",
    "\n",
    "To familairize outselves with the data, and play around with CNNs, we all decided to make our own CNN architecture and see who could get the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "DIRNAME = \"data_generation/weather_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ted's Model\n",
    "\n",
    "**Why it will win:** I chose to use more epochs and Adam as opposed to RMSProp for my optimizer. I hope this will help the model converge more towards a global minimum in the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(directory):\n",
    "  #The eventual list of all images\n",
    "  \n",
    "    images=[]\n",
    "      #The eventual list of all labels where (0,1) is rainy and (1,0) is sunny\n",
    "    labels=[]\n",
    "    for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "    if file.endswith(\".png\"):\n",
    "        fullpath=os.path.join(root,file)\n",
    "        #Convert to a One-Hot-Encoding\n",
    "        if \"sunny\" in file: \n",
    "            label=((1,0))\n",
    "        else:\n",
    "            label=((0,1))\n",
    "        images.append(fullpath)\n",
    "        labels.append(label)\n",
    "    assert len(images)==len(labels)\n",
    "    return images,labels\n",
    "\n",
    "images, labels = preprocess(DIRNAME)\n",
    "\n",
    "x_train,  x_test, y_train, y_test =  train_test_split(images, labels, test_size=0.25)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "\n",
    "print('Not using data augmentation.')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)\n",
    "\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eric's Model\n",
    "\n",
    "**Why it will win:** Using the ImageDataGeneration class adds more images with augmentations (I used featurewise_std_normalization, zca_whitening, rotation_range, width_shift_range, height_shift_range, horizontal_flip, rescale) to generate extra training data to learn from. It will also help the model generalize to unseen new data. This will give my model the advantage over the rest!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "\n",
    "DIR = DIRNAME\n",
    "\n",
    "files = list(os.scandir(DIR))\n",
    "X = [f.name for f in files]\n",
    "y = ['sun' if f.name.startswith('sun') else 'rain' for f in files]\n",
    "\n",
    "suns = sum((1 for w in y if w=='sun'))\n",
    "print(suns,len(y)-suns)  \n",
    "\n",
    "# The data, split between train and test sets:\n",
    "name_train,  name_test, y_train, y_test =  train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(32, (3, 3), padding='same',input_shape=(128,128,3)),\n",
    "  Activation('relu'),\n",
    "  Conv2D(32, (3, 3)),\n",
    "  Activation('relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "\n",
    "  Conv2D(64, (3, 3), padding='same'),\n",
    "  Activation('relu'),\n",
    "  Conv2D(64, (3, 3)),\n",
    "  Activation('relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "\n",
    "  Flatten(),\n",
    "  Dense(512),\n",
    "  Activation('relu'),\n",
    "  Dropout(0.5),\n",
    "  Dense(2),\n",
    "  Activation('softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop()\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_std_normalization=True,\n",
    "    zca_whitening=True\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255)\n",
    "\n",
    "srcGen = train_datagen.flow_from_dataframe(\n",
    "    DataFrame(data={'filename':name_train,'class':y_train}),directory=DIR,target_size=(128,128),batch_size=16)\n",
    "\n",
    "dataGen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "    DataFrame(data={'filename':name_test,'class':y_test}),\n",
    "    directory=DIR,target_size=(128,128),batch_size=16)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "checkpointer = ModelCheckpoint(filepath='/data/Shared drives/Waymo Project/tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "model.fit_generator(srcGen,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=dataGen,\n",
    "                    workers=4,\n",
    "                    callbacks=[checkpointer])\n",
    "\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(dataGen, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jack's Model\n",
    "\n",
    "**Why it will win:** I decided to use a larger architecture, with larger dense layers at the end and two times as many filters in each Convolution layer. This will let the model learn more complex patterns within the data at the expense of speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "images, labels = preprocess(DIRNAME)\n",
    "\n",
    "x_train,  x_test, y_train, y_test =  train_test_split(images, labels, test_size=0.25)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "\n",
    "print('Not using data augmentation.')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)\n",
    "\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
