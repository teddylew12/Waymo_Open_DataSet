{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing the Dataset for Tensorflow Object Detection API\n",
    "\n",
    "This script takes in the TFRecord files of the dataset and creates tf.Examples that describe the Regions of Interest (ROIs) of the image that contain a object. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DIRNAME = \"path/to/file/dir/\"\n",
    "OUTPUT_PATH='/home/tedbo123/data/waymo/eval/tf_recs/4_25_eval'\n",
    "NUM_SHARDS=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set-Up**<br>\n",
    "Download and set up -> https://github.com/gdlg/simple-waymo-open-dataset-reader <br>\n",
    "Download and set up -> https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simple_waymo_open_dataset_reader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6d0971ff828a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontextlib2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msimple_waymo_open_dataset_reader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWaymoDataFileReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msimple_waymo_open_dataset_reader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_pb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msimple_waymo_open_dataset_reader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'simple_waymo_open_dataset_reader'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import io\n",
    "from io import BytesIO\n",
    "import sys\n",
    "import random\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import contextlib2\n",
    "from simple_waymo_open_dataset_reader import WaymoDataFileReader\n",
    "from simple_waymo_open_dataset_reader import dataset_pb2, label_pb2\n",
    "from simple_waymo_open_dataset_reader import utils\n",
    "\n",
    "\n",
    "from models.research.object_detection.utils import dataset_util\n",
    "from models.research.object_detection.dataset_tools import tf_record_creation_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating TF Examples**\n",
    "This follows this script https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md\n",
    "\n",
    "There is one Example per image, and each image can have 0 or more ROIs. Each examples contains the following:\n",
    "\n",
    "- **Filename**: Name of the jpg file\n",
    "- **Height**: Height of image\n",
    "- **Width**: Width of image\n",
    "- **Encoded Bytes**: Raw JPG Bytes\n",
    "- **Type of Encoding**: JPG or PNG encoding\n",
    "- **X_mins**: List of X_mins for object boxes, 1 per object\n",
    "- **X_maxs**: List of X_maxs for object boxes, 1 per object\n",
    "- **Y_mins**: List of Y_mins for object boxes, 1 per object\n",
    "- **Y_maxs**: List of Y_maxs for object boxes, 1 per object\n",
    "- **Class Label**: Class number\n",
    "- **Class Name**: Class name\n",
    "\n",
    "\n",
    "![Example Image](Images/vis8.png \"An frame from the set with Bounding Boxes\")\n",
    "\n",
    "Using this image (generated by our model in Part 4!) our dictionary might look something like this: <br>\n",
    "  filename: \"sample_image_1.png\" <br>\n",
    "  height: 1280 <br>\n",
    "  width: 900 <br>\n",
    "  X_mins=[30,45,100,...] <br>\n",
    "  X_maxs=[800,450,110,...] <br>\n",
    "  Y_mins=[400,245,730,...] <br>\n",
    "  Y_maxs=[600,845,790,...] <br>\n",
    "  labels: [1,1,1,...] <br>\n",
    "\n",
    "\n",
    "The labels are all VEHICLES, so they all have class 1. If there were pedestrians (2) or signs (3) we would see the labels change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(img,frame,img_num,frame_num,file_num):\n",
    "    encoded_image_data=img.image\n",
    "    image_format = b'jpeg'\n",
    "    xmins=[]\n",
    "    xmaxs=[]\n",
    "    ymins=[]\n",
    "    ymaxs=[]\n",
    "    classes=[]\n",
    "    classes_text=[]\n",
    "    class_names=[\"null\",b\"TYPE_UNKNOWN\",b\"TYPE_VEHICLE\",b\"TYPE_PEDESTRIAN\",b'TYPE_SIGN',b\"TYPE_CYCLIST\"]\n",
    "    bytes_img=BytesIO(img.image)\n",
    "    im=Image.open(bytes_img)\n",
    "    width, height=im.size\n",
    "    for camera_label in frame.camera_labels:\n",
    "        if camera_label.name != img.name:\n",
    "            continue\n",
    "        for label in camera_label.labels:\n",
    "            xmins.append((label.box.center_x - 0.5 * label.box.length)/width)\n",
    "            ymins.append((label.box.center_y - 0.5 * label.box.width)/width)\n",
    "            xmaxs.append((label.box.center_x + 0.5 * label.box.length)/height)\n",
    "            ymaxs.append((label.box.center_y + 0.5 * label.box.width)/height)\n",
    "            classes.append(label.type+1)\n",
    "            classes_text.append(class_names[label.type+1])\n",
    "    img_name=f\"{file_num}_{frame_num}_{img_num}.jpeg\"\n",
    "    im.save(os.path.join(\"/home/tedbo123/data/waymo/eval/jpgs/\",img_name))\n",
    "    f_name=bytes(img_name,'utf-8')\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "    'image/height': dataset_util.int64_feature(height),\n",
    "    'image/width': dataset_util.int64_feature(width),\n",
    "    'image/filename': dataset_util.bytes_feature(f_name),\n",
    "    'image/source_id': dataset_util.bytes_feature(f_name),\n",
    "    'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "    'image/format': dataset_util.bytes_feature(image_format),\n",
    "    'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "    'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "    'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "    'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "    'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "    'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop Through The Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a .tfrecord\n",
    "def main(_):\n",
    "    num_shards=NUM_SHARDS\n",
    "    output_filebase=OUTPUT_PATH\n",
    "\n",
    "    with contextlib2.ExitStack() as tf_record_close_stack:\n",
    "        output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
    "        tf_record_close_stack, output_filebase, num_shards)\n",
    "        file_num=0\n",
    "        shard_index=0\n",
    "        for tf_file in os.listdir(DIRNAME):\n",
    "            # Get an file from the list\n",
    "            tf_file=os.path.join(DIRNAME,tf_file)\n",
    "            print(tf_file)\n",
    "            datafile = WaymoDataFileReader(tf_file)\n",
    "            frame_num=0\n",
    "            for frame in datafile:\n",
    "                #Loop through each frame in the file\n",
    "                img_num=0\n",
    "                for camera_image in frame.images:\n",
    "                    #Loop through each image in the frame\n",
    "                    tf_example=create_tf_example(camera_image,frame,img_num,frame_num,file_num)\n",
    "                    output_shard_index = shard_index % num_shards\n",
    "                    output_tfrecords[output_shard_index].write(tf_example.SerializeToString())\n",
    "                    shard_index+=1\n",
    "                    img_num+=1\n",
    "                frame_num+=1\n",
    "            file_num+=1\n",
    "\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.compat.v1.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That's It!** <br>\n",
    "\n",
    "Now you have everything you need to use the Waymo Dataset on the Tensorflow Object Detection API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
