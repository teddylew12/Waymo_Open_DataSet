{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waymo Dataset \n",
    "\n",
    "To Be Added:\n",
    "Project Overview\n",
    "Goals:\n",
    "Data Type:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install waymo-open-dataset\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from waymo_open_dataset.utils import range_image_utils\n",
    "from waymo_open_dataset.utils import transform_utils\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Look at One of the files and what it contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"segment-10206293520369375008_2796_800_2816_800_with_camera_labels.tfrecord\"\n",
    "dataset=tf.data.TFRecordDataset(filename,compression_type='')\n",
    "for data in dataset:\n",
    "  frame=open_dataset.Frame()\n",
    "  frame.ParseFromString(bytearray(data.numpy()))\n",
    "  #Get the location\n",
    "  print(\"The location is %s \"%frame.context)\n",
    "  #Get the number of cars,signs and pedestrians\n",
    "  \n",
    "  cars=frame.context.stats.laser_object_counts[0].count\n",
    "  signs=frame.context.stats.laser_object_counts[1].count\n",
    "  print(\"Number of Cars: %s,\\nNumber of signs: %s\"%(cars,signs))\n",
    "  break\n",
    "'''\n",
    "stats {\n",
    "laser_object_counts {\n",
    "type: TYPE_VEHICLE\n",
    "count: 6\n",
    "}\n",
    "laser_object_counts {\n",
    "type: TYPE_SIGN\n",
    "count: 4\n",
    "}\n",
    "time_of_day: \"Night\"\n",
    "location: \"location_phx\"\n",
    "weather: \"sunny\"\n",
    "camera_object_counts {\n",
    "type: TYPE_VEHICLE\n",
    "count: 4\n",
    "}\n",
    "}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Take a look at the image being used\n",
    "This is taken from the colab tutorial (LINK TO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used for showing the pictures\n",
    "import matplotlib.pyplot as plt\n",
    "#Used for creating the bouding boxes\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def show_camera_image(camera_image, camera_labels, layout, cmap=None):\n",
    "  \"\"\"Show a camera image and the given camera labels.\"\"\"\n",
    "  #Create a general area for the output of the function\n",
    "  ax = plt.subplot(*layout)\n",
    "\n",
    "  # Draw the camera labels.\n",
    "  for camera_labels in frame.camera_labels:\n",
    "    # Ignore camera labels that do not correspond to this camera.\n",
    "    if camera_labels.name != camera_image.name:\n",
    "      continue\n",
    "\n",
    "    # Iterate over the individual labels.\n",
    "    for label in camera_labels.labels:\n",
    "      # Draw the object bounding box.\n",
    "      ax.add_patch(patches.Rectangle(\n",
    "        xy=(label.box.center_x - 0.5 * label.box.length,\n",
    "            label.box.center_y - 0.5 * label.box.width),\n",
    "        width=label.box.length,\n",
    "        height=label.box.width,\n",
    "        linewidth=1,\n",
    "        edgecolor='red',\n",
    "        facecolor='none'))\n",
    "\n",
    "  # Show the camera image.\n",
    "  plt.imshow(tf.image.decode_jpeg(camera_image.image), cmap=cmap)\n",
    "  plt.title(open_dataset.CameraName.Name.Name(camera_image.name))\n",
    "  plt.grid(False)\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "\n",
    "for index, image in enumerate(frame.images):\n",
    "  show_camera_image(image, frame.camera_labels, [3, 3, index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_totals():\n",
    "    '''\n",
    "    Gets the weather amount for both\n",
    "    '''\n",
    "def augment_weather_images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "direc='/data/Shared drives/Waymo Project/Data'\n",
    "#Need to Create a List of Dictionaries in the following format, will make it a pickle\n",
    "'''\n",
    "roidbs (list[dict]):\n",
    "        Produce \"roidbs\" as a list of dict, each dict corresponds to one image with k>=0 instances.\n",
    "        and the following keys are expected for training:\n",
    "        file_name: str, full path to the image\n",
    "        boxes: numpy array of kx4 floats, each row is [x1, y1, x2, y2]\n",
    "        class: numpy array of k integers, in the range of [1, #categories], NOT [0, #categories)\n",
    "        is_crowd: k booleans. Use k False if you don't know what it means.\n",
    "        \n",
    "boundingboxtypes=[\"unknown\",\"Vehicle\"]\n",
    "boundingboxlist=[]\n",
    "dataset=tf.data.TFRecordDataset(file,compression_type='')\n",
    "for data in dataset:\n",
    "      frame=open_dataset.Frame()\n",
    "      frame.ParseFromString(bytearray(data.numpy()))\n",
    "      break\n",
    "for camlabel in frame.camera_labels:\n",
    "  for label in camlabel.labels:\n",
    "\n",
    "    boundingboxlist.append([file,\n",
    "                            label.box.center_x - 0.5 * label.box.length,\n",
    "                            label.box.center_y - 0.5 * label.box.width,\n",
    "                            label.box.center_x + 0.5 * label.box.length,\n",
    "                            label.box.center_y + 0.5 * label.box.width,\n",
    "                            boundingboxtypes[label.type]])\n",
    "#for index, image in enumerate(frame.images):\n",
    "# show_camera_image(image, frame.camera_labels, [3, 3, index+1])\n",
    "\n",
    "print(boundingboxlist)\n",
    "'''\n",
    "\n",
    "# Use this funciton to save the images for presentation\n",
    "def saveimagesmaskrcnn(d):\n",
    "  toBePickled=[]\n",
    "  labelsMsg = open_dataset.CameraLabels()\n",
    "  \n",
    "  switch = False #set to true if you wanna save\n",
    "\n",
    "# only use one file, change to static file (200 images in a frame sequence and 5 sides)\n",
    "  with os.scandir(d) as it:\n",
    "    for entry in tqdm(it):\n",
    "      if entry.name.endswith('.tfrecord'):\n",
    "        imageLabels={}\n",
    "        filename=entry.path\n",
    "        # main line\n",
    "        dataset=tf.data.TFRecordDataset(filename)\n",
    "        \n",
    "        d_name= entry.name.split(\"-\")[-1][:-9]\n",
    "# use frame images at a certain place to find certain image\n",
    "# do imagename.image to get actual image\n",
    "# \n",
    "        i_frame = 0\n",
    "        # go through each of 200 images and operate on eachone\n",
    "        for data in dataset:\n",
    "          #exact these 2\n",
    "          frame=open_dataset.Frame()\n",
    "          frame.ParseFromString(bytearray(data.numpy()))\n",
    "          #Save image to new folder and use the name in dict\n",
    "          counter = 0\n",
    "          for lbl,img in zip(frame.camera_labels,frame.images):\n",
    "            name=f\"{d_name}_frame_{i_frame:05}_image_{counter:05}.png\"\n",
    "\n",
    "            if switch:\n",
    "              # use these 3 lines to go from array of stuff to an actual image\n",
    "              #im.show shows video of the image\n",
    "              #show_camera_image function above to get from a file to all the images\n",
    "              # can add a rectangle with the actual box, save and GIF\n",
    "              decoded=tf.image.decode_jpeg(img.image)\n",
    "              tonumpy=decoded.numpy()\n",
    "              im=Image.fromarray(tonumpy)\n",
    "              im.save(os.path.join('/data/Shared drives/Waymo Project/Data/FastImages',name))           \n",
    "\n",
    "            labelsMsg.CopyFrom(lbl)\n",
    "            boxes = np.array([[label.box.center_x - 0.5 * label.box.length,\n",
    "                              label.box.center_y - 0.5 * label.box.width,\n",
    "                              label.box.center_x + 0.5 * label.box.length,\n",
    "                              label.box.center_y + 0.5 * label.box.width] for label in lbl.labels])\n",
    "            labels = np.array([label.type+1 for label in labelsMsg.labels])\n",
    "\n",
    "            toBePickled.append({'file_name':name,'boxes':boxes, 'class':labels, 'is_crowd':False})\n",
    "            counter+=1\n",
    "          i_frame += 1\n",
    "\n",
    "  return toBePickled\n",
    "              \n",
    "import pickle\n",
    "p=saveimagesmaskrcnn(direc)\n",
    "with open(os.path.join('/data/Shared drives/Waymo Project/Data/FastImages',\"via_region_data.pickle.pickle\"),'wb') as fileObj:\n",
    "  pickle.dump(p,fileObj)\n",
    "\n",
    "\n",
    "with open(os.path.join('/data/Shared drives/Waymo Project/Data/FastImages',\"via_region_data.pickle.pickle\"),'rb') as istream:\n",
    "    my_pickle = pickle.load(istream)\n",
    "    # obj = [{\"file_name\":e['file'],'boxes':e['boxes'],'class':e['labels'],'is_crowd':e['is_crowd']} for e in pickle.load(istream)]\n",
    "    # pickle.dump(obj,ostream)\n",
    "    #print(obj)\n",
    "\n",
    "import pandas as pd\n",
    "df_pickle = pd.DataFrame(my_pickle)\n",
    "df_pickle.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Pipeline! Returns a list of images and their respective labels\n",
    "\n",
    "def preprocess(directory):\n",
    "  #The eventual list of all images\n",
    "  \n",
    "  images=[]\n",
    "  #The eventual list of all labels where (0,1) is rainy and (1,0) is sunny\n",
    "  labels=[]\n",
    "  for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "      if file.endswith(\".png\"):\n",
    "        fullpath=os.path.join(root,file)\n",
    "        #Convert to a One-Hot-Encoding\n",
    "        if \"sunny\" in file: \n",
    "          label=((1,0))\n",
    "        else:\n",
    "          label=((0,1))\n",
    "        images.append(fullpath)\n",
    "        labels.append(label)\n",
    "  assert len(images)==len(labels)\n",
    "  return images,labels\n",
    "direct=\"YOUR FILEPATH HERE\"\n",
    "preprocess(direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 7\n",
    "num_classes = 2\n",
    "epochs = 13\n",
    "num_predictions = 20\n",
    "DIR = \"/data/Shared drives/Waymo Project/Data/Images\"\n",
    "\n",
    "files = list(os.scandir(DIR))\n",
    "X = [f.name for f in files]\n",
    "y = ['sun' if f.name.startswith('sun') else 'rain' for f in files]\n",
    "\n",
    "suns = sum((1 for w in y if w=='sun'))\n",
    "print(suns,len(y)-suns)  \n",
    "\n",
    "# The data, split between train and test sets:\n",
    "name_train,  name_test, y_train, y_test =  train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(32, (3, 3), padding='same',input_shape=(128,128,3)),\n",
    "  Activation('relu'),\n",
    "  Conv2D(32, (3, 3)),\n",
    "  Activation('relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "\n",
    "  Conv2D(64, (3, 3), padding='same'),\n",
    "  Activation('relu'),\n",
    "  Conv2D(64, (3, 3)),\n",
    "  Activation('relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.25),\n",
    "\n",
    "  Flatten(),\n",
    "  Dense(512),\n",
    "  Activation('relu'),\n",
    "  Dropout(0.5),\n",
    "  Dense(num_classes),\n",
    "  Activation('softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop()\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#print('Not using data augmentation.')\n",
    "#model.fit(x_train, y_train,\n",
    "#          batch_size=batch_size,\n",
    "#          epochs=epochs,\n",
    "#          validation_data=(x_test, y_test),\n",
    "#          shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "#datagen.fit(x_train)\n",
    "\n",
    "srcGen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "    DataFrame(data={'filename':name_train,'class':y_train}),directory=DIR,target_size=(128,128),batch_size=16)\n",
    "\n",
    "dataGen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "    DataFrame(data={'filename':name_test,'class':y_test}),\n",
    "    directory=DIR,target_size=(128,128),batch_size=16,)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "checkpointer = ModelCheckpoint(filepath='/data/Shared drives/Waymo Project/tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "model.fit_generator(srcGen,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=dataGen,\n",
    "                    workers=4,\n",
    "                    callbacks=[checkpointer])\n",
    "\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(dataGen, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
